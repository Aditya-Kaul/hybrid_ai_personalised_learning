[
    {
      "module_name": "The Machine Learning Landscape",
      "exercises": [
        "How would you define Machine Learning?",
        "Can you name four types of problems where ML shines?",
        "What is a labeled training set?",
        "What are the two most common supervised tasks?",
        "Can you name four of the main challenges in Machine Learning?",
        "What is out-of-core learning?",
        " If your model performs great on the training data but generalizes poorly to new instances, what is happening? Can you name three possible solutions?",
        "What is a test set, and why would you want to use it?",
        "What is the train-dev set, when do you need it, and how do you use it?",
        "What can go wrong if you tune hyperparameters using the test set?"
      ]
    },
    {
      "module_name": "End-to-End Machine Learning Project",
      "exercises": [
        "Get a Housing Dataset from R. Kelley Pace and Ronald Barry, “Sparse Spatial Autoregressions,” Statistics & Probability. \n Try a Support Vector Machine regressor(sklearn.svm.SVR) with various hyperparameters, such as kernel='linear'(with various values for the C hyperparameter) or kernel = 'rbf' (with various values for the C and gamma hyperparameter ). Don’t worry about what these hyperparameter mean for now. How does the best predictor perform?",
        "Try replacing GridSearchCV with RandomizedSearchCV",
        "Try adding a transformer in the preparation pipeline to select only the most important attributes.",
        " Try creating a single pipeline that does the full data preparation plus the final prediction."
      ]
    },
    {
      "module_name": "Classification",
      "exercises": [
        "Try to build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set. Hint: the KNeighborsClassifiers works quite well for this task; you just need to find good hyperparameter values (try a grid search on the weights and n_neighbors hyperparameter)",
        "Write a function that can shift an MNIST image in any direction (left, right, up, or down) by one pixel.5 Then, for each image in the training set, create four shifted copies (one per direction) and add them to the training set. Finally, train your best model on this expanded training set and measure its accuracy on the test set. You should observe that your model performs even better now! This technique of artificially growing the training set is called data augmentation or training set expansion.",
        "Explore precision-recall tradeoff for a trained model.",
        "Experiment with different classifiers and compare their ROC curves.",
        "Train and fine-tune a decision tree for the MNIST dataset."
      ]
    },
    {
      "module_name": "Training Models",
      "exercises": [
        "Which Linear Regression training algorithm can you use if you have a training set with millions of features?",
        "Suppose the features in your training set have very different scales. Which algorithms might suffer from this, and how? What can you do about it?",
        "Can Gradient Descent get stuck in a local minimum when training a Logistic Regression model?",
        "Suppose you use Batch Gradient Descent and you plot the validation error at every epoch. If you notice that the validation error consistently goes up, what is likely going on? How can you fix this?",
        "Suppose you are using Polynomial Regression. You plot the learning curves and you notice that there is a large gap between the training error and the validation error. What is happening? What are three ways to solve this?",
        "Suppose you want to classify pictures as outdoor/indoor and daytime/nighttime. Should you implement two Logistic Regression classifiers or one Softmax Regression classifier?",
        "Implement Batch Gradient Descent with early stopping for Softmax Regression (without using Scikit-Learn)."
      ]
    },
    {
      "module_name": "Support Vector Machines",
      "exercises": [
        "What is the fundamental idea behind Support Vector Machines",
        "What is a support vector?",
        "Why is it important to scale the inputs when using SVMs?",
        "Can an SVM classifier output a confidence score when it classifies an instance? What about a probability?",
        "Train an SVM classifier on the MNIST dataset. Since SVM classifiers are binary classifiers, you will need to use one-versus-the-rest to classify all 10 digits. You may want to tune the hyperparameters using small validation sets to speed up the process. What accuracy can you reach?",
        "Train an SVM regressor on the California housing dataset."
      ]
    },
    {
      "module_name": "Decision Trees",
      "exercises": [
        "What is the approximate depth of a Decision Tree trained (without restrictions) on a training set with one million instances?",
        "Is a node’s Gini impurity generally lower or greater than its parent’s? Is it generally lower/greater, or always lower/greater?",
        "If a Decision Tree is underfitting the training set, is it a good idea to try scaling the input features?",
        "How do I train and fine-tune a Decision Tree for the moons dataset?\n            \n            1. Use `sklearn.datasets.make_moons` to generate a moons dataset.\n            2. Use `sklearn.model_selection.train_test_split` to split the dataset into a training set and a test set.\n            3. Use grid search with cross-validation (with the help of `sklearn.model_selection.GridSearchCV`) to find good hyperparameter values for a `DecisionTreeClassifier`. Hint: try various values for `max_depth`, `min_samples_split`, etc.\n            4. Train it on the full training set using these hyperparameters, and measure your model’s performance on the test set. You should get roughly 85% to 87% accuracy.\n            "
      ]
    },
    {
      "module_name": "Ensemble Learning and Random Forests",
      "exercises": [
        "If you have trained five different models on the exact same training data, and they all achieve 95% precision, is there any chance that you can combine these models to get better results? If so, how? If not, why?",
        "What is the difference between hard and soft voting classifiers?",
        "Is it possible to speed up training of a bagging ensemble by distributing it across multiple servers? What about pasting ensembles, boosting ensembles, Random Forests, or stacking ensembles?",
        "What is the benefit of out-of-bag evaluation?",
        "If your AdaBoost ensemble underfits the training data, which hyperparameters should you tweak and how?",
        "If your Gradient Boosting ensemble overfits the training set, should you increase or decrease the learning rate?",
        "Load the MNIST data (introduced in Chapter 3), and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation, and 10,000 for testing). Then train various classifiers, such as a Random Forest classifier, an Extra-Trees classifier, and an SVM classifier. Next, try to combine them into an ensemble that outperforms each individual classifier on the validation set, using soft or hard voting. Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers?"
      ]
    },
    {
      "module_name": "Dimensionality Reduction",
      "exercises": [
        "What are the main motivations for reducing a dataset’s dimensionality? What are the main drawbacks?",
        "What is the curse of dimensionality?",
        "Once a dataset’s dimensionality has been reduced, is it possible to reverse the operation? If so, how? If not, why?",
        "Can PCA be used to reduce the dimensionality of a highly nonlinear dataset?",
        "Suppose you perform PCA on a 1,000-dimensional dataset, setting the explained variance ratio to 95%. How many dimensions will the resulting dataset have?",
        "Use t-SNE to reduce the MNIST dataset down to two dimensions and plot the result using Matplotlib. You can use a scatterplot using 10 different colors to represent each image’s target class. Alternatively, you can replace each dot in the scatterplot with the corresponding instance’s class (a digit from 0 to 9), or even plot scaled-down versions of the digit images themselves (if you plot all digits, the visualization will be too cluttered, so you should either draw a random sample or plot an instance only if no other instance has already been plotted at a close distance). You should get a nice visualization with well-separated clusters of digits. Try using other dimensionality reduction algorithms such as PCA, LLE, or MDS and compare the resulting visualizations."
      ]
    },
    {
      "module_name": "Unsupervised Learning Techniques",
      "exercises": [
        "How would you define clustering? Can you name a few clustering algorithms?",
        "What are some of the main applications of clustering algorithms?",
        "Describe two techniques to select the right number of clusters when using K-Means.",
        "What is label propagation? Why would you implement it, and how?",
        "Can you name two clustering algorithms that can scale to large datasets? And two that look for regions of high density?",
        "What is a Gaussian mixture? What tasks can you use it for?",
        "Train a Gaussian mixture model on the Olivetti faces dataset. To speed up the algorithm, you should probably reduce the dataset’s dimensionality (e.g., use PCA, preserving 99% of the variance). Use the model to generate some new faces (using the method)and visualize them (if you used PCA, you will need to use its inverse_transform() method). Try to modify some images (e.g., rotate, flip, darken) and see if the model can detect the anomalies (i.e., compare the output of the score_samples() method for normal images and for anomalies)."
      ]
    },
    {
        "module_name": "Introduction to Artificial Neural Networks with Keras",
        "exercises": [
            "Why was the logistic activation function a key ingredient in training the first MLPs?",
            "Name three popular activation functions.",
            "What is backpropagation and how does it work? What is the difference between backpropagation and reverse-mode autodiff?", 
            "Can you list all the hyperparameters you can tweak in a basic MLP? If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?"
        ]
    }
  ]